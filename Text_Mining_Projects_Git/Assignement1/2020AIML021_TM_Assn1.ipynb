{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Import required libraries - 2 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\pjatthi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "import math\n",
    "#from googletrans import Translator\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.cluster import MiniBatchKMeans\n",
    "#!pip install -q wordcloud\n",
    "#!pip install -q kmeans\n",
    "import wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the facebook dataset \n",
    "df = pd.read_csv('Corona_NLP_train.csv',encoding='latin1',parse_dates=['TweetAt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41157, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserName  ScreenName   Location    TweetAt  \\\n",
       "0      3799       48751     London 2020-03-16   \n",
       "1      3800       48752         UK 2020-03-16   \n",
       "2      3801       48753  Vagabonds 2020-03-16   \n",
       "3      3802       48754        NaN 2020-03-16   \n",
       "4      3803       48755        NaN 2020-03-16   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserName                  int64\n",
       "ScreenName                int64\n",
       "Location                 object\n",
       "TweetAt          datetime64[ns]\n",
       "OriginalTweet            object\n",
       "Sentiment                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2dd22356947c>:1: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.\n",
      "  df.describe(include=['object','datetime'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32567</td>\n",
       "      <td>41157</td>\n",
       "      <td>41157</td>\n",
       "      <td>41157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12220</td>\n",
       "      <td>30</td>\n",
       "      <td>41157</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>London</td>\n",
       "      <td>2020-03-20 00:00:00</td>\n",
       "      <td>A byproduct of COVID-19: #cyberfraud. Now is t...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>540</td>\n",
       "      <td>3448</td>\n",
       "      <td>1</td>\n",
       "      <td>11422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-12-04 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location              TweetAt  \\\n",
       "count     32567                41157   \n",
       "unique    12220                   30   \n",
       "top      London  2020-03-20 00:00:00   \n",
       "freq        540                 3448   \n",
       "first       NaN  2020-01-04 00:00:00   \n",
       "last        NaN  2020-12-04 00:00:00   \n",
       "\n",
       "                                            OriginalTweet Sentiment  \n",
       "count                                               41157     41157  \n",
       "unique                                              41157         5  \n",
       "top     A byproduct of COVID-19: #cyberfraud. Now is t...  Positive  \n",
       "freq                                                    1     11422  \n",
       "first                                                 NaN       NaN  \n",
       "last                                                  NaN       NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=['object','datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df.drop(['UserName','ScreenName','TweetAt','Location'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet           Sentiment\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral\n",
       "1  advice Talk to your neighbours family to excha...            Positive\n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive\n",
       "3  My food stock is not the only one which is emp...            Positive\n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41157 entries, 0 to 41156\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   OriginalTweet  41157 non-null  object\n",
      " 1   Sentiment      41157 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 643.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OriginalTweet    0\n",
       "Sentiment        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Read dataset and perfom Text processing for the tweets ( Remove Stop words , special characters and convert the text to lowercase ) - 3 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "word = list(set(words.words()))\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def textCleaning(text):\n",
    "    text = text.lower()\n",
    "    #text = \" \".join([w for w in nltk.wordpunct_tokenize(text) if w.lower() in words or not w.isalpha()])\n",
    "    #text = word_tokenize(text)\n",
    "    ## use regular expression to remove url from the data\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    ## remove mentions, hashtag and emojios from the data and also remove the non english characters\n",
    "    text = ' '.join(re.sub(\"(@[A-Za-z0–9]+)|([^-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",text).split())\n",
    "    text = \" \".join([porter.stem(i) for i in word_tokenize(text)])\n",
    "    ## remove punctuation from the data\n",
    "    text = \" \".join([i for i in word_tokenize(text) if i not in string.punctuation])\n",
    "    ## remove numbers \n",
    "    text = \" \".join([i for i in word_tokenize(text) if not i.isdigit()])\n",
    "    ## remove stopwords from the data\n",
    "    text = \" \".join([i for i in word_tokenize(text) if i not in set(stopwords.words('english'))])\n",
    "    text = \" \".join([wordnet_lemmatizer.lemmatize(i) for i in word_tokenize(text)])\n",
    "   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset['clean_tweets'] = df_subset.OriginalTweet.apply(lambda x: textCleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.to_csv('cleanData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_subset.clean_tweets[~(df_subset.clean_tweets == '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           OriginalTweet           Sentiment  \\\n",
      "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
      "1      advice Talk to your neighbours family to excha...            Positive   \n",
      "2      Coronavirus Australia: Woolworths to give elde...            Positive   \n",
      "3      My food stock is not the only one which is emp...            Positive   \n",
      "4      Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
      "...                                                  ...                 ...   \n",
      "41152  Airline pilots offering to stock supermarket s...             Neutral   \n",
      "41153  Response to complaint not provided citing COVI...  Extremely Negative   \n",
      "41154  You know itÂs getting tough when @KameronWild...            Positive   \n",
      "41155  Is it wrong that the smell of hand sanitizer i...             Neutral   \n",
      "41156  @TartiiCat Well new/used Rift S are going for ...            Negative   \n",
      "\n",
      "                                            clean_tweets  \n",
      "0                                                  gahan  \n",
      "1      advic talk neighbour famili exchang phone numb...  \n",
      "2      coronaviru australia woolworth give elderli di...  \n",
      "3      food stock onli one empti plea panic enough fo...  \n",
      "4      readi go supermarket dure covid outbreak becau...  \n",
      "...                                                  ...  \n",
      "41152  airlin pilot offer stock supermarket shelv nz ...  \n",
      "41153  respons complaint provid cite covid- relat del...  \n",
      "41154  know get tough ration toilet paper coronaviru ...  \n",
      "41155  wrong smell hand sanit start turn coronaviru c...  \n",
      "41156  well new use rift go amazon rn although normal...  \n",
      "\n",
      "[41157 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_subset.replace({\"positive\":1,\"negative\":0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>gahan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>advic talk neighbour famili exchang phone numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>coronaviru australia woolworth give elderli di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>food stock onli one empti plea panic enough fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "      <td>readi go supermarket dure covid outbreak becau...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       OriginalTweet           Sentiment  \\\n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral   \n",
       "1  advice Talk to your neighbours family to excha...            Positive   \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive   \n",
       "3  My food stock is not the only one which is emp...            Positive   \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative   \n",
       "\n",
       "                                        clean_tweets  \n",
       "0                                              gahan  \n",
       "1  advic talk neighbour famili exchang phone numb...  \n",
       "2  coronaviru australia woolworth give elderli di...  \n",
       "3  food stock onli one empti plea panic enough fo...  \n",
       "4  readi go supermarket dure covid outbreak becau...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Using the train_test_split function of Sklearn, Split train and test dataset - 1 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_subset.clean_tweets,df_subset.Sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Create pipeline and define parameters for GridSearch ( You might Refer the code below ) - 1 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "tuned_parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': [1, 1e-1, 1e-2]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy: 38.17%\n",
      "\n",
      " [[  30    0  763    6  295]\n",
      " [   0   57   38    3 1233]\n",
      " [   5    2  900   20 1059]\n",
      " [   1    2  268  162 1093]\n",
      " [   1    4  277   20 1993]]\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.81      0.03      0.05      1094\n",
      "Extremely Positive       0.88      0.04      0.08      1331\n",
      "          Negative       0.40      0.45      0.43      1986\n",
      "           Neutral       0.77      0.11      0.19      1526\n",
      "          Positive       0.35      0.87      0.50      2295\n",
      "\n",
      "          accuracy                           0.38      8232\n",
      "         macro avg       0.64      0.30      0.25      8232\n",
      "      weighted avg       0.59      0.38      0.30      8232\n",
      "\n",
      "0.3816812439261419\n"
     ]
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)\n",
    "score = text_clf.score(X_test, y_test)\n",
    "prediction = text_clf.predict(X_test)\n",
    "print('\\naccuracy: {}%'.format(round(accuracy_score(y_test, prediction)*100,2)))\n",
    "print('\\n',confusion_matrix(y_test, prediction))\n",
    "print('\\n',classification_report(y_test, prediction))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3816812439261419"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(text_clf, 'your_pipeline.pkl')\n",
    "joblib.load('your_pipeline.pkl').score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Perform classification (using GridSearch) - 3 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vect', CountVectorizer()),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__alpha': [1, 0.1, 0.01],\n",
       "                         'tfidf__norm': ('l1', 'l2'),\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__ngram_range': [(1, 1), (1, 2), (2, 2)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(text_clf, tuned_parameters, cv=10, verbose=1,n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Print the confusion matrix, accuracy, F1 score on the test dataset - 2 Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params are : {'clf__alpha': 0.01, 'tfidf__norm': 'l2', 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}\n",
      "Best training accuracy: 0.451\n",
      "Test set accuracy score for best params: 0.460 \n",
      "\n",
      "accuracy: 46.03%\n",
      "\n",
      " [[ 427   15  452   42  158]\n",
      " [  14  553  125   40  599]\n",
      " [ 209   72  932  166  607]\n",
      " [  41   71  282  662  470]\n",
      " [  68  314  477  221 1215]]\n",
      "\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Extremely Negative       0.56      0.39      0.46      1094\n",
      "Extremely Positive       0.54      0.42      0.47      1331\n",
      "          Negative       0.41      0.47      0.44      1986\n",
      "           Neutral       0.59      0.43      0.50      1526\n",
      "          Positive       0.40      0.53      0.45      2295\n",
      "\n",
      "          accuracy                           0.46      8232\n",
      "         macro avg       0.50      0.45      0.46      8232\n",
      "      weighted avg       0.48      0.46      0.46      8232\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#grid_search.fit(X_train, y_train)\n",
    "print('Best params are : %s' % grid_search.best_params_)\n",
    "# Best training data accuracy\n",
    "print('Best training accuracy: %.3f' % grid_search.best_score_)\n",
    "# Predict on test data with best params\n",
    "y_pred = grid_search.predict(X_test)\n",
    "# Test data accuracy of model with best params\n",
    "print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "# Track best (highest test accuracy) model\n",
    "print('\\naccuracy: {}%'.format(round(accuracy_score(y_test, y_pred)*100,2)))\n",
    "best_acc = accuracy_score(y_test, y_pred)\n",
    "print('\\n',confusion_matrix(y_test, y_pred))\n",
    "print('\\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
