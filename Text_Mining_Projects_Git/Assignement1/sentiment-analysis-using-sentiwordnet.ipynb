{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python37\\site-packages\\matplotlib\\__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.2.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from IPython.display import clear_output\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode (connected = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('movie_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making two copies of Reviews to edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing Positive -> 1 and Negative -> 0\n",
    "\n",
    "data.replace({\"positive\":1,\"negative\":0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edits After Removing Stopwords\n",
    "Edited_Review = data['review'].copy()\n",
    "data['Review_without_stopwords'] = Edited_Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Having a look at 1st five reviews in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Review_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...          1   \n",
       "1  A wonderful little production. <br /><br />The...          1   \n",
       "2  I thought this was a wonderful way to spend ti...          1   \n",
       "3  Basically there's a family where a little boy ...          0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
       "\n",
       "                            Review_without_stopwords  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production. <br /><br />The...  \n",
       "2  I thought this was a wonderful way to spend ti...  \n",
       "3  Basically there's a family where a little boy ...  \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess Reviews data\n",
    "def preprocess_Reviews_data(data,name):\n",
    "    # Proprocessing the data\n",
    "    data[name]=data[name].str.lower()\n",
    "    # Code to remove the Hashtags from the text\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\B#\\S+','',x))\n",
    "    # Code to remove the links from the text\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n",
    "    # Code to remove the Special characters from the text \n",
    "    data[name]=data[name].apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n",
    "    # Code to substitute the multiple spaces with single spaces\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n",
    "    # Code to remove all the single characters in the text\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n",
    "    # Remove the twitter handlers\n",
    "    data[name]=data[name].apply(lambda x:re.sub('@[^\\s]+','',x))\n",
    "\n",
    "# Function to tokenize and remove the stopwords    \n",
    "def rem_stopwords_tokenize(data,name):\n",
    "      \n",
    "    def getting(sen):\n",
    "        example_sent = sen\n",
    "        \n",
    "        filtered_sentence = [] \n",
    "\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "\n",
    "        word_tokens = word_tokenize(example_sent) \n",
    "        \n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "        \n",
    "        return filtered_sentence\n",
    "    # Using \"getting(sen)\" function to append edited sentence to data\n",
    "    x=[]\n",
    "    for i in data[name].values:\n",
    "        x.append(getting(i))\n",
    "    data[name]=x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def Lemmatization(data,name):\n",
    "    def getting2(sen):\n",
    "        \n",
    "        example = sen\n",
    "        output_sentence =[]\n",
    "        word_tokens2 = word_tokenize(example)\n",
    "        lemmatized_output = [lemmatizer.lemmatize(w) for w in word_tokens2]\n",
    "        \n",
    "        # Remove characters which have length less than 2  \n",
    "        without_single_chr = [word for word in lemmatized_output if len(word) > 2]\n",
    "        # Remove numbers\n",
    "        cleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]\n",
    "        \n",
    "        return cleaned_data_title\n",
    "    # Using \"getting2(sen)\" function to append edited sentence to data\n",
    "    x=[]\n",
    "    for i in data[name].values:\n",
    "        x.append(getting2(i))\n",
    "    data[name]=x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting all the texts back to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences(data,name):\n",
    "    data[name]=data[name].apply(lambda x:' '.join([i+' ' for i in x]))\n",
    "    # Removing double spaces if created\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the preprocessing function to preprocess the hotel data\n",
    "preprocess_Reviews_data(data,'Review_without_stopwords')\n",
    "# Using tokenizer and removing the stopwords\n",
    "rem_stopwords_tokenize(data,'Review_without_stopwords')\n",
    "# Converting all the texts back to sentences\n",
    "make_sentences(data,'Review_without_stopwords')\n",
    "\n",
    "#Edits After Lemmatization\n",
    "final_Edit = data['Review_without_stopwords'].copy()\n",
    "data[\"After_lemmatization\"] = final_Edit\n",
    "\n",
    "# Using the Lemmatization function to lemmatize the hotel data\n",
    "Lemmatization(data,'After_lemmatization')\n",
    "# Converting all the texts back to sentences\n",
    "make_sentences(data,'After_lemmatization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of Preprocessing data (Removing stopwords & Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Review_without_stopwords</th>\n",
       "      <th>After_lemmatization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>one reviewer mentioned watching episode hooked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought waswonderful way spend time ontoo hot ...</td>\n",
       "      <td>thought waswonderful way spend time ontoo hot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically therea family wherelittle boy jake t...</td>\n",
       "      <td>basically therea family wherelittle boy jake t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteilove time money isvisually stunni...</td>\n",
       "      <td>petter matteilove time money isvisually stunni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>1</td>\n",
       "      <td>probably time favorite moviestory selflessness...</td>\n",
       "      <td>probably time favorite moviestory selflessness...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...          1   \n",
       "1  A wonderful little production. <br /><br />The...          1   \n",
       "2  I thought this was a wonderful way to spend ti...          1   \n",
       "3  Basically there's a family where a little boy ...          0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
       "5  Probably my all-time favorite movie, a story o...          1   \n",
       "\n",
       "                            Review_without_stopwords  \\\n",
       "0  one reviewers mentioned watching 1 oz episode ...   \n",
       "1  wonderful little production br br filming tech...   \n",
       "2  thought waswonderful way spend time ontoo hot ...   \n",
       "3  basically therea family wherelittle boy jake t...   \n",
       "4  petter matteilove time money isvisually stunni...   \n",
       "5  probably time favorite moviestory selflessness...   \n",
       "\n",
       "                                 After_lemmatization  \n",
       "0  one reviewer mentioned watching episode hooked...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought waswonderful way spend time ontoo hot ...  \n",
       "3  basically therea family wherelittle boy jake t...  \n",
       "4  petter matteilove time money isvisually stunni...  \n",
       "5  probably time favorite moviestory selflessness...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we are working with sentiwordnet we need to know the characterstic of the word for which we want to know the sentiment . So for finding that position of the word here we are gonna use nltk which tells us about the position of the word which then is used to get the sentiment using the sentiwordnet . We then average out the score for both the positive and the negative score from the whole sentence .\n",
    "The positions compatible with the sentiwordnet are:\n",
    "* n - NOUN\n",
    "* v - VERB\n",
    "* a - ADJECTIVE\n",
    "* s - ADJECTIVE SATELLITE\n",
    "* r - ADVERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       -2.125\n",
      "1        5.000\n",
      "2        0.250\n",
      "3        1.750\n",
      "4        6.625\n",
      "5        3.000\n",
      "6        0.250\n",
      "7        1.375\n",
      "8        1.125\n",
      "9        1.250\n",
      "10       2.250\n",
      "11      -0.750\n",
      "12       2.625\n",
      "13      -0.625\n",
      "14       0.875\n",
      "15      -0.375\n",
      "16       0.750\n",
      "17      -0.625\n",
      "18      -0.625\n",
      "19       2.125\n",
      "20      -0.750\n",
      "21      -1.000\n",
      "22       1.500\n",
      "23      -3.125\n",
      "24      -0.625\n",
      "25      -0.750\n",
      "26      -0.375\n",
      "27      -1.125\n",
      "28      -2.375\n",
      "29      -4.750\n",
      "         ...  \n",
      "49970   -1.500\n",
      "49971   -0.125\n",
      "49972   -1.612\n",
      "49973    3.375\n",
      "49974    0.625\n",
      "49975   -0.625\n",
      "49976    1.250\n",
      "49977    0.375\n",
      "49978   -0.375\n",
      "49979    0.875\n",
      "49980    1.625\n",
      "49981    5.625\n",
      "49982    0.500\n",
      "49983    3.125\n",
      "49984    0.750\n",
      "49985    3.375\n",
      "49986    2.250\n",
      "49987    1.375\n",
      "49988    3.125\n",
      "49989    0.375\n",
      "49990   -2.125\n",
      "49991    1.250\n",
      "49992   -2.750\n",
      "49993    3.375\n",
      "49994   -3.147\n",
      "49995    0.125\n",
      "49996   -0.500\n",
      "49997   -2.500\n",
      "49998   -4.375\n",
      "49999    0.750\n",
      "Name: senti_score, Length: 50000, dtype: float64\n",
      "<bound method NDFrame.head of                                                   review  sentiment  \\\n",
      "0      One of the other reviewers has mentioned that ...          1   \n",
      "1      A wonderful little production. <br /><br />The...          1   \n",
      "2      I thought this was a wonderful way to spend ti...          1   \n",
      "3      Basically there's a family where a little boy ...          0   \n",
      "4      Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
      "5      Probably my all-time favorite movie, a story o...          1   \n",
      "6      I sure would like to see a resurrection of a u...          1   \n",
      "7      This show was an amazing, fresh & innovative i...          0   \n",
      "8      Encouraged by the positive comments about this...          0   \n",
      "9      If you like original gut wrenching laughter yo...          1   \n",
      "10     Phil the Alien is one of those quirky films wh...          0   \n",
      "11     I saw this movie when I was about 12 when it c...          0   \n",
      "12     So im not a big fan of Boll's work but then ag...          0   \n",
      "13     The cast played Shakespeare.<br /><br />Shakes...          0   \n",
      "14     This a fantastic movie of three prisoners who ...          1   \n",
      "15     Kind of drawn in by the erotic scenes, only to...          0   \n",
      "16     Some films just simply should not be remade. T...          1   \n",
      "17     This movie made it into one of my top 10 most ...          0   \n",
      "18     I remember this film,it was the first film i h...          1   \n",
      "19     An awful film! It must have been up against so...          0   \n",
      "20     After the success of Die Hard and it's sequels...          1   \n",
      "21     I had the terrible misfortune of having to vie...          0   \n",
      "22     What an absolutely stunning movie, if you have...          1   \n",
      "23     First of all, let's get a few things straight ...          0   \n",
      "24     This was the worst movie I saw at WorldFest an...          0   \n",
      "25     The Karen Carpenter Story shows a little more ...          1   \n",
      "26     \"The Cell\" is an exotic masterpiece, a dizzyin...          1   \n",
      "27     This film tried to be too many things all at o...          0   \n",
      "28     This movie was so frustrating. Everything seem...          0   \n",
      "29     'War movie' is a Hollywood genre that has been...          1   \n",
      "...                                                  ...        ...   \n",
      "49970  This movie is a total dog. I found myself stra...          0   \n",
      "49971  With several name actors (Lance Henrikson, Dav...          0   \n",
      "49972  The future of fantasy never looked so dark! Ch...          0   \n",
      "49973  The title leads viewers to believe that this i...          0   \n",
      "49974  For the most part, \"Michael\" is a disaster  t...          0   \n",
      "49975  90 minutes of Mindy...Mindy is a tease to boyf...          0   \n",
      "49976  I saw the movie in the theater at its release,...          1   \n",
      "49977  Dog Bite Dog isn't going to be for everyone, b...          1   \n",
      "49978  Halloween is one of those movies that gets you...          1   \n",
      "49979  I saw this with high expectations. Come on, it...          0   \n",
      "49980  A stunning film of high quality.<br /><br />Ap...          1   \n",
      "49981  And I repeat, please do not see this movie! Th...          0   \n",
      "49982  To be hones, I used to like this show and watc...          0   \n",
      "49983  I loved it, having been a fan of the original ...          1   \n",
      "49984  Hello it is I Derrick Cannon and I welcome you...          0   \n",
      "49985  Imaginary Heroes is clearly the best film of t...          1   \n",
      "49986  This movie is a disgrace to the Major League F...          0   \n",
      "49987  A remake of Alejandro Amenabar's Abre los Ojos...          0   \n",
      "49988  When I first tuned in on this morning news, I ...          0   \n",
      "49989  I got this one a few weeks ago and love it! It...          1   \n",
      "49990  Lame, lame, lame!!! A 90-minute cringe-fest th...          0   \n",
      "49991  Les Visiteurs, the first movie about the medie...          0   \n",
      "49992  John Garfield plays a Marine who is blinded by...          1   \n",
      "49993  Robert Colomb has two full-time jobs. He's kno...          0   \n",
      "49994  This is your typical junk comedy.<br /><br />T...          0   \n",
      "49995  I thought this movie did a down right good job...          1   \n",
      "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0   \n",
      "49997  I am a Catholic taught in parochial elementary...          0   \n",
      "49998  I'm going to have to disagree with the previou...          0   \n",
      "49999  No one expects the Star Trek movies to be high...          0   \n",
      "\n",
      "                                Review_without_stopwords  \\\n",
      "0      one reviewers mentioned watching 1 oz episode ...   \n",
      "1      wonderful little production br br filming tech...   \n",
      "2      thought waswonderful way spend time ontoo hot ...   \n",
      "3      basically therea family wherelittle boy jake t...   \n",
      "4      petter matteilove time money isvisually stunni...   \n",
      "5      probably time favorite moviestory selflessness...   \n",
      "6      sure would like seeresurrection ofup dated sea...   \n",
      "7      show amazing fresh innovative idea 70when firs...   \n",
      "8      encouraged positive comments film herewas look...   \n",
      "9      like original gut wrenching laughter like movi...   \n",
      "10     phil alien one quirky films humour based aroun...   \n",
      "11     saw movie whenwas 12 came outrecall scariest s...   \n",
      "12     im notbig fan bollwork many areenjoyed movie p...   \n",
      "13     cast played shakespeare br br shakespeare lost...   \n",
      "14     thisfantastic movie three prisoners become fam...   \n",
      "15     kind drawn erotic scenes realize one amateuris...   \n",
      "16     films simply remade one notbad film fails capt...   \n",
      "17     movie made one top 10 awful movies horrible br...   \n",
      "18     remember film first filmhad watched cinema pic...   \n",
      "19     awful film must real stinkers nominated golden...   \n",
      "20     success die hard itsequels itno surprise reall...   \n",
      "21     terrible misfortune view thismovie itentirety ...   \n",
      "22     absolutely stunning movie 2 5 hrs kill watch w...   \n",
      "23     first letgetfew things straight herei anime fa...   \n",
      "24     worst moviesaw worldfest also received least a...   \n",
      "25     karen carpenter story showslittle singer karen...   \n",
      "26     cell exotic masterpiecedizzying trip vast mind...   \n",
      "27     film tried many things stinging political sati...   \n",
      "28     movie frustrating everything seemed energetic ...   \n",
      "29     war movie ishollywood genre done redone many t...   \n",
      "...                                                  ...   \n",
      "49970  movie istotal dogfound straining find anything...   \n",
      "49971  several name actors lance henrikson david warn...   \n",
      "49972  future fantasy never looked dark christopher l...   \n",
      "49973  title leads viewers believe isfun movie watch ...   \n",
      "49974  part michael isdisaster ten minutes charm nine...   \n",
      "49975  90 minutes mindy mindy istease boyfriend bill ...   \n",
      "49976  saw movie theater release watched vhs tape yea...   \n",
      "49977  dog bite dog isngoing everyone butreally enjoy...   \n",
      "49978  halloween one movies gets skin deep opinion sc...   \n",
      "49979  saw high expectations come akshay kumar govind...   \n",
      "49980  stunning film high quality br br apparently ba...   \n",
      "49981  andrepeat please see movie thanreview iswarnin...   \n",
      "49982  honesused like show watch regularly thank godd...   \n",
      "49983  loved beenfan original serieshave always wonde...   \n",
      "49984  hello isderrick cannon andwelcome first ever c...   \n",
      "49985  imaginary heroes clearly best film year wascom...   \n",
      "49986  movie isdisgrace major league franchiselive mi...   \n",
      "49987  remake alejandro amenabarabre los ojos time wi...   \n",
      "49988  whenfirst tuned morning newsthought wow finall...   \n",
      "49989  got onefew weeks ago love itmodern light fille...   \n",
      "49990  lame lame lame90 minute cringe fest that89 min...   \n",
      "49991  les visiteurs first movie medieval time travel...   \n",
      "49992  john garfield playsmarine blinded bygrenade fi...   \n",
      "49993  robert colomb two full time jobs heknown throu...   \n",
      "49994  typical junk comedy br br almost laughs genuin...   \n",
      "49995  thought movie diddown right good job wasnas cr...   \n",
      "49996  bad plot bad dialogue bad acting idiotic direc...   \n",
      "49997  amcatholic taught parochial elementary schools...   \n",
      "49998  igoing disagree previous comment side maltin o...   \n",
      "49999  one expects star trek movies high art fans exp...   \n",
      "\n",
      "                                     After_lemmatization  \\\n",
      "0      one reviewer mentioned watching episode hooked...   \n",
      "1      wonderful little production filming technique ...   \n",
      "2      thought waswonderful way spend time ontoo hot ...   \n",
      "3      basically therea family wherelittle boy jake t...   \n",
      "4      petter matteilove time money isvisually stunni...   \n",
      "5      probably time favorite moviestory selflessness...   \n",
      "6      sure would like seeresurrection ofup dated sea...   \n",
      "7      show amazing fresh innovative idea 70when firs...   \n",
      "8      encouraged positive comment film herewas looki...   \n",
      "9      like original gut wrenching laughter like movi...   \n",
      "10     phil alien one quirky film humour based around...   \n",
      "11     saw movie whenwas came outrecall scariest scen...   \n",
      "12     notbig fan bollwork many areenjoyed movie post...   \n",
      "13     cast played shakespeare shakespeare lost brapp...   \n",
      "14     thisfantastic movie three prisoner become famo...   \n",
      "15     kind drawn erotic scene realize one amateurish...   \n",
      "16     film simply remade one notbad film fails captu...   \n",
      "17     movie made one top awful movie horrible wasna ...   \n",
      "18     remember film first filmhad watched cinema pic...   \n",
      "19     awful film must real stinker nominated golden ...   \n",
      "20     success die hard itsequels itno surprise reall...   \n",
      "21     terrible misfortune view thismovie itentirety ...   \n",
      "22     absolutely stunning movie kill watch wonregret...   \n",
      "23     first letgetfew thing straight herei anime fan...   \n",
      "24     worst moviesaw worldfest also received least a...   \n",
      "25     karen carpenter story showslittle singer karen...   \n",
      "26     cell exotic masterpiecedizzying trip vast mind...   \n",
      "27     film tried many thing stinging political satir...   \n",
      "28     movie frustrating everything seemed energetic ...   \n",
      "29     war movie ishollywood genre done redone many t...   \n",
      "...                                                  ...   \n",
      "49970  movie istotal dogfound straining find anything...   \n",
      "49971  several name actor lance henrikson david warne...   \n",
      "49972  future fantasy never looked dark christopher l...   \n",
      "49973  title lead viewer believe isfun movie watch pr...   \n",
      "49974  part michael isdisaster ten minute charm ninet...   \n",
      "49975  minute mindy mindy istease boyfriend bill mind...   \n",
      "49976  saw movie theater release watched vhs tape yea...   \n",
      "49977  dog bite dog isngoing everyone butreally enjoy...   \n",
      "49978  halloween one movie get skin deep opinion scar...   \n",
      "49979  saw high expectation come akshay kumar govinda...   \n",
      "49980  stunning film high quality apparently based tr...   \n",
      "49981  andrepeat please see movie thanreview iswarnin...   \n",
      "49982  honesused like show watch regularly thank godd...   \n",
      "49983  loved beenfan original serieshave always wonde...   \n",
      "49984  hello isderrick cannon andwelcome first ever c...   \n",
      "49985  imaginary hero clearly best film year wascompl...   \n",
      "49986  movie isdisgrace major league franchiselive mi...   \n",
      "49987  remake alejandro amenabarabre los ojos time wi...   \n",
      "49988  whenfirst tuned morning newsthought wow finall...   \n",
      "49989  got onefew week ago love itmodern light filled...   \n",
      "49990  lame lame lame90 minute cringe fest that89 min...   \n",
      "49991  visiteurs first movie medieval time traveler a...   \n",
      "49992  john garfield playsmarine blinded bygrenade fi...   \n",
      "49993  robert colomb two full time job heknown throug...   \n",
      "49994  typical junk comedy almost laugh genuine momen...   \n",
      "49995  thought movie diddown right good job wasnas cr...   \n",
      "49996  bad plot bad dialogue bad acting idiotic direc...   \n",
      "49997  amcatholic taught parochial elementary school ...   \n",
      "49998  igoing disagree previous comment side maltin o...   \n",
      "49999  one expects star trek movie high art fan expec...   \n",
      "\n",
      "                                                pos_tags  senti_score  \n",
      "0      [(one, CD), (reviewer, NN), (mentioned, VBD), ...       -2.125  \n",
      "1      [(wonderful, JJ), (little, JJ), (production, N...        5.000  \n",
      "2      [(thought, VBN), (waswonderful, JJ), (way, NN)...        0.250  \n",
      "3      [(basically, RB), (therea, JJ), (family, NN), ...        1.750  \n",
      "4      [(petter, NN), (matteilove, NN), (time, NN), (...        6.625  \n",
      "5      [(probably, RB), (time, NN), (favorite, JJ), (...        3.000  \n",
      "6      [(sure, RB), (would, MD), (like, VB), (seeresu...        0.250  \n",
      "7      [(show, NN), (amazing, JJ), (fresh, JJ), (inno...        1.375  \n",
      "8      [(encouraged, VBN), (positive, JJ), (comment, ...        1.125  \n",
      "9      [(like, IN), (original, JJ), (gut, NN), (wrenc...        1.250  \n",
      "10     [(phil, NN), (alien, VBZ), (one, CD), (quirky,...        2.250  \n",
      "11     [(saw, JJ), (movie, NN), (whenwas, NN), (came,...       -0.750  \n",
      "12     [(notbig, JJ), (fan, NN), (bollwork, VBD), (ma...        2.625  \n",
      "13     [(cast, NN), (played, VBD), (shakespeare, NN),...       -0.625  \n",
      "14     [(thisfantastic, JJ), (movie, NN), (three, CD)...        0.875  \n",
      "15     [(kind, NN), (drawn, NN), (erotic, JJ), (scene...       -0.375  \n",
      "16     [(film, NN), (simply, RB), (remade, VB), (one,...        0.750  \n",
      "17     [(movie, NN), (made, VBD), (one, CD), (top, JJ...       -0.625  \n",
      "18     [(remember, VB), (film, NN), (first, RB), (fil...       -0.625  \n",
      "19     [(awful, JJ), (film, NN), (must, MD), (real, J...        2.125  \n",
      "20     [(success, NN), (die, VB), (hard, JJ), (itsequ...       -0.750  \n",
      "21     [(terrible, JJ), (misfortune, NN), (view, NN),...       -1.000  \n",
      "22     [(absolutely, RB), (stunning, JJ), (movie, NN)...        1.500  \n",
      "23     [(first, RB), (letgetfew, JJ), (thing, NN), (s...       -3.125  \n",
      "24     [(worst, JJS), (moviesaw, NN), (worldfest, NN)...       -0.625  \n",
      "25     [(karen, NNS), (carpenter, VBP), (story, NN), ...       -0.750  \n",
      "26     [(cell, NN), (exotic, JJ), (masterpiecedizzyin...       -0.375  \n",
      "27     [(film, NN), (tried, VBD), (many, JJ), (thing,...       -1.125  \n",
      "28     [(movie, NN), (frustrating, VBG), (everything,...       -2.375  \n",
      "29     [(war, NN), (movie, NN), (ishollywood, NN), (g...       -4.750  \n",
      "...                                                  ...          ...  \n",
      "49970  [(movie, NN), (istotal, JJ), (dogfound, NN), (...       -1.500  \n",
      "49971  [(several, JJ), (name, NN), (actor, NN), (lanc...       -0.125  \n",
      "49972  [(future, JJ), (fantasy, NN), (never, RB), (lo...       -1.612  \n",
      "49973  [(title, JJ), (lead, NN), (viewer, NN), (belie...        3.375  \n",
      "49974  [(part, NN), (michael, NN), (isdisaster, NN), ...        0.625  \n",
      "49975  [(minute, NN), (mindy, NN), (mindy, JJ), (iste...       -0.625  \n",
      "49976  [(saw, NN), (movie, NN), (theater, NN), (relea...        1.250  \n",
      "49977  [(dog, NN), (bite, NN), (dog, NN), (isngoing, ...        0.375  \n",
      "49978  [(halloween, JJ), (one, CD), (movie, NN), (get...       -0.375  \n",
      "49979  [(saw, RB), (high, JJ), (expectation, NN), (co...        0.875  \n",
      "49980  [(stunning, VBG), (film, NN), (high, JJ), (qua...        1.625  \n",
      "49981  [(andrepeat, NN), (please, NN), (see, VB), (mo...        5.625  \n",
      "49982  [(honesused, VBN), (like, IN), (show, NN), (wa...        0.500  \n",
      "49983  [(loved, VBN), (beenfan, NN), (original, JJ), ...        3.125  \n",
      "49984  [(hello, NN), (isderrick, NN), (cannon, NN), (...        0.750  \n",
      "49985  [(imaginary, JJ), (hero, NN), (clearly, RB), (...        3.375  \n",
      "49986  [(movie, NN), (isdisgrace, NN), (major, JJ), (...        2.250  \n",
      "49987  [(remake, VB), (alejandro, NN), (amenabarabre,...        1.375  \n",
      "49988  [(whenfirst, RB), (tuned, VBN), (morning, NN),...        3.125  \n",
      "49989  [(got, VBD), (onefew, JJ), (week, NN), (ago, R...        0.375  \n",
      "49990  [(lame, NN), (lame, NN), (lame90, JJ), (minute...       -2.125  \n",
      "49991  [(visiteurs, NNS), (first, JJ), (movie, NN), (...        1.250  \n",
      "49992  [(john, NN), (garfield, NN), (playsmarine, NN)...       -2.750  \n",
      "49993  [(robert, JJ), (colomb, NN), (two, CD), (full,...        3.375  \n",
      "49994  [(typical, JJ), (junk, NN), (comedy, NN), (alm...       -3.147  \n",
      "49995  [(thought, VBN), (movie, NN), (diddown, NN), (...        0.125  \n",
      "49996  [(bad, JJ), (plot, NN), (bad, JJ), (dialogue, ...       -0.500  \n",
      "49997  [(amcatholic, JJ), (taught, VBD), (parochial, ...       -2.500  \n",
      "49998  [(igoing, VBG), (disagree, VBP), (previous, JJ...       -4.375  \n",
      "49999  [(one, CD), (expects, VBZ), (star, NN), (trek,...        0.750  \n",
      "\n",
      "[50000 rows x 6 columns]>\n"
     ]
    }
   ],
   "source": [
    "pos=neg=obj=count=0\n",
    "\n",
    "postagging = []\n",
    "\n",
    "for review in data['After_lemmatization']:\n",
    "    list = word_tokenize(review)\n",
    "    postagging.append(nltk.pos_tag(list))\n",
    "\n",
    "data['pos_tags'] = postagging\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    return None\n",
    "\n",
    "\n",
    "# Returns list of pos-neg and objective score. But returns empty list if not present in senti wordnet.\n",
    "def get_sentiment(word,tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    \n",
    "    if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "        return []\n",
    "\n",
    "    #Lemmatization\n",
    "    lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "    if not lemma:\n",
    "        return []\n",
    "\n",
    "    #Synset is a special kind of a simple interface that is present in NLTK to look up words in WordNet. \n",
    "    #Synset instances are the groupings of synonymous words that express the same concept. \n",
    "    #Some of the words have only one Synset and some have several.\n",
    "    synsets = wn.synsets(word, pos=wn_tag)\n",
    "    if not synsets:\n",
    "        return []\n",
    "\n",
    "    # Take the first sense, the most common\n",
    "    synset = synsets[0]\n",
    "    swn_synset = swn.senti_synset(synset.name())\n",
    "\n",
    "    return [synset.name(), swn_synset.pos_score(),swn_synset.neg_score(),swn_synset.obj_score()]\n",
    "\n",
    "    pos=neg=obj=count=0\n",
    "    \n",
    "    ###################################################################################\n",
    "senti_score = []\n",
    "\n",
    "for pos_val in data['pos_tags']:\n",
    "    senti_val = [get_sentiment(x,y) for (x,y) in pos_val]\n",
    "    for score in senti_val:\n",
    "        try:\n",
    "            pos = pos + score[1]  #positive score is stored at 2nd position\n",
    "            neg = neg + score[2]  #negative score is stored at 3rd position\n",
    "        except:\n",
    "            continue\n",
    "    senti_score.append(pos - neg)\n",
    "    pos=neg=0    \n",
    "    \n",
    "data['senti_score'] = senti_score\n",
    "print(data['senti_score'])\n",
    "\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall=[]\n",
    "for i in range(len(data)):\n",
    "    if data['senti_score'][i]>= 0.05:\n",
    "        overall.append('Positive')\n",
    "    elif data['senti_score'][i]<= -0.05:\n",
    "        overall.append('Negative')\n",
    "    else:\n",
    "        overall.append('Neutral')\n",
    "data['Overall Sentiment']=overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Review_without_stopwords</th>\n",
       "      <th>After_lemmatization</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>senti_score</th>\n",
       "      <th>Overall Sentiment</th>\n",
       "      <th>reviews_text_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>one reviewer mentioned watching episode hooked...</td>\n",
       "      <td>[(one, CD), (reviewer, NN), (mentioned, VBD), ...</td>\n",
       "      <td>-2.125</td>\n",
       "      <td>Negative</td>\n",
       "      <td>one reviewer mentioned watching episode hooked...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>[(wonderful, JJ), (little, JJ), (production, N...</td>\n",
       "      <td>5.000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "      <td>thought waswonderful way spend time ontoo hot ...</td>\n",
       "      <td>thought waswonderful way spend time ontoo hot ...</td>\n",
       "      <td>[(thought, VBN), (waswonderful, JJ), (way, NN)...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>Positive</td>\n",
       "      <td>thought waswonderful way spend time ontoo hot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "      <td>basically therea family wherelittle boy jake t...</td>\n",
       "      <td>basically therea family wherelittle boy jake t...</td>\n",
       "      <td>[(basically, RB), (therea, JJ), (family, NN), ...</td>\n",
       "      <td>1.750</td>\n",
       "      <td>Positive</td>\n",
       "      <td>basically therea family wherelittle boy jake t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "      <td>petter matteilove time money isvisually stunni...</td>\n",
       "      <td>petter matteilove time money isvisually stunni...</td>\n",
       "      <td>[(petter, NN), (matteilove, NN), (time, NN), (...</td>\n",
       "      <td>6.625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>petter matteilove time money isvisually stunni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>1</td>\n",
       "      <td>probably time favorite moviestory selflessness...</td>\n",
       "      <td>probably time favorite moviestory selflessness...</td>\n",
       "      <td>[(probably, RB), (time, NN), (favorite, JJ), (...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>probably time favorite moviestory selflessness...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>1</td>\n",
       "      <td>sure would like seeresurrection ofup dated sea...</td>\n",
       "      <td>sure would like seeresurrection ofup dated sea...</td>\n",
       "      <td>[(sure, RB), (would, MD), (like, VB), (seeresu...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>Positive</td>\n",
       "      <td>sure would like seeresurrection ofup dated sea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>0</td>\n",
       "      <td>show amazing fresh innovative idea 70when firs...</td>\n",
       "      <td>show amazing fresh innovative idea 70when firs...</td>\n",
       "      <td>[(show, NN), (amazing, JJ), (fresh, JJ), (inno...</td>\n",
       "      <td>1.375</td>\n",
       "      <td>Positive</td>\n",
       "      <td>show amazing fresh innovative idea 70when firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>0</td>\n",
       "      <td>encouraged positive comments film herewas look...</td>\n",
       "      <td>encouraged positive comment film herewas looki...</td>\n",
       "      <td>[(encouraged, VBN), (positive, JJ), (comment, ...</td>\n",
       "      <td>1.125</td>\n",
       "      <td>Positive</td>\n",
       "      <td>encouraged positive comment film herewas looki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>like original gut wrenching laughter like movi...</td>\n",
       "      <td>like original gut wrenching laughter like movi...</td>\n",
       "      <td>[(like, IN), (original, JJ), (gut, NN), (wrenc...</td>\n",
       "      <td>1.250</td>\n",
       "      <td>Positive</td>\n",
       "      <td>like original gut wrenching laughter like movi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...          1   \n",
       "1  A wonderful little production. <br /><br />The...          1   \n",
       "2  I thought this was a wonderful way to spend ti...          1   \n",
       "3  Basically there's a family where a little boy ...          0   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1   \n",
       "5  Probably my all-time favorite movie, a story o...          1   \n",
       "6  I sure would like to see a resurrection of a u...          1   \n",
       "7  This show was an amazing, fresh & innovative i...          0   \n",
       "8  Encouraged by the positive comments about this...          0   \n",
       "9  If you like original gut wrenching laughter yo...          1   \n",
       "\n",
       "                            Review_without_stopwords  \\\n",
       "0  one reviewers mentioned watching 1 oz episode ...   \n",
       "1  wonderful little production br br filming tech...   \n",
       "2  thought waswonderful way spend time ontoo hot ...   \n",
       "3  basically therea family wherelittle boy jake t...   \n",
       "4  petter matteilove time money isvisually stunni...   \n",
       "5  probably time favorite moviestory selflessness...   \n",
       "6  sure would like seeresurrection ofup dated sea...   \n",
       "7  show amazing fresh innovative idea 70when firs...   \n",
       "8  encouraged positive comments film herewas look...   \n",
       "9  like original gut wrenching laughter like movi...   \n",
       "\n",
       "                                 After_lemmatization  \\\n",
       "0  one reviewer mentioned watching episode hooked...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought waswonderful way spend time ontoo hot ...   \n",
       "3  basically therea family wherelittle boy jake t...   \n",
       "4  petter matteilove time money isvisually stunni...   \n",
       "5  probably time favorite moviestory selflessness...   \n",
       "6  sure would like seeresurrection ofup dated sea...   \n",
       "7  show amazing fresh innovative idea 70when firs...   \n",
       "8  encouraged positive comment film herewas looki...   \n",
       "9  like original gut wrenching laughter like movi...   \n",
       "\n",
       "                                            pos_tags  senti_score  \\\n",
       "0  [(one, CD), (reviewer, NN), (mentioned, VBD), ...       -2.125   \n",
       "1  [(wonderful, JJ), (little, JJ), (production, N...        5.000   \n",
       "2  [(thought, VBN), (waswonderful, JJ), (way, NN)...        0.250   \n",
       "3  [(basically, RB), (therea, JJ), (family, NN), ...        1.750   \n",
       "4  [(petter, NN), (matteilove, NN), (time, NN), (...        6.625   \n",
       "5  [(probably, RB), (time, NN), (favorite, JJ), (...        3.000   \n",
       "6  [(sure, RB), (would, MD), (like, VB), (seeresu...        0.250   \n",
       "7  [(show, NN), (amazing, JJ), (fresh, JJ), (inno...        1.375   \n",
       "8  [(encouraged, VBN), (positive, JJ), (comment, ...        1.125   \n",
       "9  [(like, IN), (original, JJ), (gut, NN), (wrenc...        1.250   \n",
       "\n",
       "  Overall Sentiment                                   reviews_text_new  \n",
       "0          Negative  one reviewer mentioned watching episode hooked...  \n",
       "1          Positive  wonderful little production filming technique ...  \n",
       "2          Positive  thought waswonderful way spend time ontoo hot ...  \n",
       "3          Positive  basically therea family wherelittle boy jake t...  \n",
       "4          Positive  petter matteilove time money isvisually stunni...  \n",
       "5          Positive  probably time favorite moviestory selflessness...  \n",
       "6          Positive  sure would like seeresurrection ofup dated sea...  \n",
       "7          Positive  show amazing fresh innovative idea 70when firs...  \n",
       "8          Positive  encouraged positive comment film herewas looki...  \n",
       "9          Positive  like original gut wrenching laughter like movi...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d084f35278>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(data['Overall Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews_text_new'] = data['After_lemmatization'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 134. GiB for an array with shape (50000, 359320) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-a39f1d7a147d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviews_text_new'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    960\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 962\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    963\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1185\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1187\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 134. GiB for an array with shape (50000, 359320) and data type int64"
     ]
    }
   ],
   "source": [
    "# The following code creates a word-document matrix.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(data['reviews_text_new'])\n",
    "df = pd.DataFrame(X.toarray(), columns = vec.get_feature_names())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(data['reviews_text_new'])\n",
    "vect.get_feature_names()\n",
    "# transform training data into a 'document-term matrix'\n",
    "simple_train_dtm = vect.transform(data['reviews_text_new'])\n",
    "print(simple_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a python object of the class CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_counts = CountVectorizer(tokenizer= word_tokenize, # type of tokenization\n",
    "                             ngram_range=(1,3)) # number of n-grams\n",
    "\n",
    "bow_data = bow_counts.fit_transform(data['reviews_text_new'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_data, # Features\n",
    "                                                                    data['Overall Sentiment'], # Target variable\n",
    "                                                                    test_size = 0.2, # 20% test size\n",
    "                                                                    random_state = 0) # random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.73      0.77      2955\n",
      "     Neutral       0.75      0.01      0.03       213\n",
      "    Positive       0.87      0.94      0.91      6832\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.81      0.56      0.57     10000\n",
      "weighted avg       0.85      0.86      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "### Training the model \n",
    "lr_model_all = LogisticRegression() # Logistic regression\n",
    "lr_model_all.fit(X_train_bow, y_train_bow) # Fitting a logistic regression model\n",
    "\n",
    "## Predicting the output\n",
    "test_pred_lr_all = lr_model_all.predict(X_test_bow) # Class prediction\n",
    "\n",
    "\n",
    "## Calculate key performance metrics\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "# Print a classification report\n",
    "print(classification_report(y_test_bow,test_pred_lr_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "noise_words = []\n",
    "### Creating a python object of the class CountVectorizer\n",
    "tfidf_counts = TfidfVectorizer(tokenizer= word_tokenize, # type of tokenization\n",
    "                               stop_words=noise_words, # List of stopwords\n",
    "                               ngram_range=(1,1)) # number of n-grams\n",
    "\n",
    "tfidf_data = tfidf_counts.fit_transform(data['reviews_text_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_data,\n",
    "                                                                            data['Overall Sentiment'],\n",
    "                                                                            test_size = 0.2,\n",
    "                                                                            random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.67      0.75      2955\n",
      "     Neutral       0.00      0.00      0.00       213\n",
      "    Positive       0.85      0.95      0.90      6832\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.56      0.54      0.55     10000\n",
      "weighted avg       0.83      0.85      0.84     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Setting up the model class\n",
    "lr_model_tf_idf = LogisticRegression()\n",
    "\n",
    "## Training the model \n",
    "lr_model_tf_idf.fit(X_train_tfidf,y_train_tfidf)\n",
    "\n",
    "## Prediciting the results\n",
    "test_pred_lr_all = lr_model_tf_idf.predict(X_test_tfidf)\n",
    "\n",
    "## Calculate key performance metrics\n",
    "\n",
    "\n",
    "# Print a classification report\n",
    "print(classification_report(y_test_tfidf,test_pred_lr_all))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
